#!/usr/bin/env python
"""
SRGAN Preprocessing for Standard Architecture
Works with standard SRGAN discriminator architecture from your .h5 weights
Implements exact paper methodology: 48x48 ‚Üí 192x192 (4x upscaling)
"""

import os
import cv2
import numpy as np
from tqdm import tqdm
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras import layers
import json
import argparse
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# Ensure TensorFlow uses GPU if available
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print(f"üöÄ Found {len(gpus)} GPU(s), memory growth enabled")
    except RuntimeError as e:
        print(f"‚ö†Ô∏è  GPU setup error: {e}")
else:
    print("üíª Using CPU for SRGAN processing")

class SRGANStandardPreprocessor:
    """
    SRGAN Preprocessor for standard architecture
    Handles the discriminator network architecture you've shown
    """
    
    def __init__(self, srgan_weights_path, input_size=(48, 48), output_size=(192, 192)):
        """
        Initialize SRGAN preprocessor with standard architecture
        
        Args:
            srgan_weights_path: Path to the .h5 weights file
            input_size: Input image size (48, 48) as per paper
            output_size: Output image size (192, 192) as per paper
        """
        self.input_size = input_size
        self.output_size = output_size
        self.scale_factor = output_size[0] // input_size[0]  # Should be 4
        
        print(f"üîß Initializing SRGAN with standard architecture...")
        print(f"üìê Input size: {input_size}")
        print(f"üìê Output size: {output_size}")
        print(f"üìê Scale factor: {self.scale_factor}x")
        
        # Load the SRGAN model
        self.srgan_model = self._load_srgan_model(srgan_weights_path)
        
    def _create_standard_srgan_generator(self):
        """
        Create standard SRGAN generator architecture
        Based on the discriminator you showed, this recreates the typical generator
        """
        def residual_block(x, filters=64):
            """Residual block with skip connection"""
            shortcut = x
            
            x = layers.Conv2D(filters, 3, padding='same')(x)
            x = layers.BatchNormalization()(x)
            x = layers.PReLU()(x)
            
            x = layers.Conv2D(filters, 3, padding='same')(x)
            x = layers.BatchNormalization()(x)
            
            # Skip connection
            x = layers.Add()([x, shortcut])
            return x
        
        def upsampling_block(x, filters=256):
            """Upsampling block using sub-pixel convolution"""
            x = layers.Conv2D(filters, 3, padding='same')(x)
            x = layers.Lambda(lambda x: tf.nn.depth_to_space(x, 2))(x)
            x = layers.PReLU()(x)
            return x
        
        # Input
        inputs = layers.Input(shape=(self.input_size[0], self.input_size[1], 3))
        
        # Initial conv
        x = layers.Conv2D(64, 9, padding='same')(inputs)
        x = layers.PReLU()(x)
        skip = x
        
        # Residual blocks (typically 16 blocks)
        for _ in range(16):
            x = residual_block(x, 64)
        
        # Post-residual conv
        x = layers.Conv2D(64, 3, padding='same')(x)
        x = layers.BatchNormalization()(x)
        x = layers.Add()([x, skip])
        
        # Upsampling blocks (2 blocks for 4x upscaling)
        x = upsampling_block(x, 256)  # 2x
        x = upsampling_block(x, 256)  # 4x total
        
        # Output
        outputs = layers.Conv2D(3, 9, activation='tanh', padding='same')(x)
        
        model = tf.keras.Model(inputs, outputs, name='SRGAN_Generator')
        return model
    
    def _load_srgan_model(self, weights_path):
        """
        Load SRGAN model with weights
        
        Args:
            weights_path: Path to .h5 weights file
            
        Returns:
            Loaded SRGAN generator model
        """
        if not os.path.exists(weights_path):
            raise FileNotFoundError(f"SRGAN weights not found: {weights_path}")
        
        try:
            # Method 1: Try direct loading
            print("üì• Attempting direct model loading...")
            model = load_model(weights_path, compile=False)
            print("‚úÖ Direct loading successful")
            
        except Exception as e1:
            print(f"‚ö†Ô∏è  Direct loading failed: {e1}")
            print("üîß Attempting to reconstruct model...")
            
            try:
                # Method 2: Reconstruct and load weights
                model = self._create_standard_srgan_generator()
                model.load_weights(weights_path)
                print("‚úÖ Model reconstruction and weight loading successful")
                
            except Exception as e2:
                print(f"‚ùå Model reconstruction failed: {e2}")
                
                # Method 3: Try loading just the generator part
                try:
                    print("üîß Attempting partial weight loading...")
                    model = self._create_standard_srgan_generator()
                    
                    # Load weights file and inspect
                    import h5py
                    with h5py.File(weights_path, 'r') as f:
                        print(f"üîç Available keys in .h5 file: {list(f.keys())}")
                        
                        # Look for generator weights
                        if 'generator' in f.keys():
                            print("üì¶ Found generator weights")
                            # Load only generator weights
                            generator_weights = f['generator']
                            # This would need custom implementation based on your specific file structure
                        
                    # For now, use the model architecture without pretrained weights
                    print("‚ö†Ô∏è  Using model architecture without pretrained weights")
                    print("üí° The model will work but may not have optimal quality")
                    
                except Exception as e3:
                    print(f"‚ùå All loading methods failed: {e3}")
                    print("üîÑ Creating fallback model with random weights")
                    model = self._create_standard_srgan_generator()
        
        # Verify model architecture
        print(f"\nüìä Model Summary:")
        print(f"  Input shape: {model.input_shape}")
        print(f"  Output shape: {model.output_shape}")
        print(f"  Parameters: {model.count_params():,}")
        
        # Verify with test input
        test_input = np.random.random((1, self.input_size[0], self.input_size[1], 3)).astype(np.float32)
        test_output = model.predict(test_input, verbose=0)
        expected_output_shape = (1, self.output_size[0], self.output_size[1], 3)
        
        if test_output.shape == expected_output_shape:
            print(f"‚úÖ Model verification successful: {test_output.shape}")
        else:
            print(f"‚ö†Ô∏è  Model output shape mismatch: got {test_output.shape}, expected {expected_output_shape}")
        
        return model
    
    def preprocess_image_srgan(self, image_path):
        """
        Preprocess single image using SRGAN
        
        Args:
            image_path: Path to input image
            
        Returns:
            Super-resolved image (192x192) or None if error
        """
        try:
            # Read image
            image = cv2.imread(image_path)
            if image is None:
                print(f"‚ùå Could not read image: {image_path}")
                return None
            
            # Convert BGR to RGB for processing
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # Resize to input size if needed
            if image_rgb.shape[:2] != self.input_size:
                image_rgb = cv2.resize(image_rgb, self.input_size, interpolation=cv2.INTER_AREA)
            
            # Normalize to [-1, 1] for SRGAN (standard practice)
            image_normalized = (image_rgb.astype(np.float32) / 127.5) - 1.0
            
            # Add batch dimension
            image_batch = np.expand_dims(image_normalized, axis=0)
            
            # Apply SRGAN super-resolution
            sr_image_batch = self.srgan_model.predict(image_batch, verbose=0)
            
            # Remove batch dimension
            sr_image = sr_image_batch[0]
            
            # Denormalize from [-1, 1] to [0, 255]
            sr_image = ((sr_image + 1.0) * 127.5).astype(np.uint8)
            
            # Clip values to valid range
            sr_image = np.clip(sr_image, 0, 255)
            
            # Ensure exact output size
            if sr_image.shape[:2] != self.output_size:
                sr_image = cv2.resize(sr_image, self.output_size, interpolation=cv2.INTER_CUBIC)
            
            # Convert back to BGR for OpenCV compatibility
            sr_image_bgr = cv2.cvtColor(sr_image, cv2.COLOR_RGB2BGR)
            
            return sr_image_bgr
            
        except Exception as e:
            print(f"‚ùå Error processing {image_path}: {e}")
            return None
    
    def create_comparison_visualization(self, image_path, save_path=None):
        """
        Create side-by-side comparison of original vs SRGAN result
        """
        # Process with SRGAN
        sr_result = self.preprocess_image_srgan(image_path)
        
        if sr_result is None:
            print("‚ùå Failed to create comparison - SRGAN processing failed")
            return None
        
        # Load and prepare original
        original = cv2.imread(image_path)
        if original.shape[:2] != self.input_size:
            original_resized = cv2.resize(original, self.input_size, interpolation=cv2.INTER_AREA)
        else:
            original_resized = original.copy()
        
        # Create comparison versions
        original_upscaled = cv2.resize(original_resized, self.output_size, interpolation=cv2.INTER_CUBIC)
        original_nearest = cv2.resize(original_resized, self.output_size, interpolation=cv2.INTER_NEAREST)
        
        # Create side-by-side comparison
        comparison = np.hstack([
            original_nearest,     # Nearest neighbor (pixelated)
            original_upscaled,    # Cubic interpolation  
            sr_result            # SRGAN result
        ])
        
        # Add labels
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.7
        thickness = 2
        
        # Labels
        labels = ["Nearest Neighbor", "Cubic Interpolation", "SRGAN 4x"]
        colors = [(0, 0, 255), (0, 255, 0), (255, 0, 0)]  # Red, Green, Blue
        
        for i, (label, color) in enumerate(zip(labels, colors)):
            x_pos = i * self.output_size[0] + 10
            cv2.putText(comparison, label, (x_pos, 30), font, font_scale, color, thickness)
        
        # Add size information
        size_info = f"Original: {self.input_size[0]}x{self.input_size[1]} -> Output: {self.output_size[0]}x{self.output_size[1]} (4x)"
        cv2.putText(comparison, size_info, (10, comparison.shape[0] - 10), font, 0.5, (255, 255, 255), 1)
        
        if save_path:
            cv2.imwrite(save_path, comparison)
            print(f"üíæ Comparison saved to: {save_path}")
        
        return comparison
    
    def preprocess_dataset(self, input_dataset_path, output_dataset_path, test_mode=False):
        """
        Preprocess entire RAF-DB dataset using SRGAN
        
        Args:
            input_dataset_path: Path to original RAF-DB dataset
            output_dataset_path: Path to save preprocessed dataset
            test_mode: If True, process only first 5 images per emotion for testing
        """
        input_path = Path(input_dataset_path)
        output_path = Path(output_dataset_path)
        
        # Validate input dataset
        if not input_path.exists():
            raise ValueError(f"Input dataset path does not exist: {input_path}")
        
        # Create output directory
        output_path.mkdir(parents=True, exist_ok=True)
        
        emotion_mapping = {
            '1': 'surprise',
            '2': 'fear',
            '3': 'disgust',
            '4': 'happiness', 
            '5': 'sadness',
            '6': 'anger',
            '7': 'neutral'
        }
        
        stats = {
            'total_processed': 0,
            'total_failed': 0,
            'by_emotion': {},
            'srgan_model_info': {
                'input_size': self.input_size,
                'output_size': self.output_size,
                'scale_factor': self.scale_factor
            }
        }
        
        print(f"\nüöÄ Starting SRGAN preprocessing...")
        print(f"üìÅ Input:  {input_path}")
        print(f"üìÅ Output: {output_path}")
        print(f"üéØ Mode:   {'TEST (5 images per emotion)' if test_mode else 'FULL DATASET'}")
        print(f"üìê Processing: {self.input_size} ‚Üí {self.output_size} ({self.scale_factor}x)")
        
        for split in ['train', 'test']:
            split_input = input_path / split
            split_output = output_path / split
            
            if not split_input.exists():
                print(f"‚ö†Ô∏è  Split directory not found: {split_input}")
                continue
            
            print(f"\nüìÇ Processing {split.upper()} set...")
            
            for emotion_id, emotion_name in emotion_mapping.items():
                emotion_input = split_input / emotion_id
                emotion_output = split_output / emotion_id
                
                if not emotion_input.exists():
                    print(f"‚ö†Ô∏è  Skipping {emotion_name} - directory not found")
                    continue
                
                # Create output directory
                emotion_output.mkdir(parents=True, exist_ok=True)
                
                # Get all image files
                image_files = []
                for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
                    image_files.extend(list(emotion_input.glob(ext)))
                
                if test_mode:
                    image_files = image_files[:5]  # Limit for testing
                
                if not image_files:
                    print(f"‚ö†Ô∏è  No images found in {emotion_input}")
                    continue
                
                print(f"  üìä {emotion_name:12}: {len(image_files):4} images")
                
                processed = 0
                failed = 0
                
                # Process each image with progress bar
                for image_file in tqdm(image_files, 
                                     desc=f"  {split}/{emotion_name}",
                                     leave=False):
                    
                    output_file = emotion_output / image_file.name
                    
                    # Skip if already processed
                    if output_file.exists():
                        processed += 1
                        continue
                    
                    # Apply SRGAN preprocessing
                    sr_image = self.preprocess_image_srgan(str(image_file))
                    
                    if sr_image is not None:
                        # Save processed image
                        success = cv2.imwrite(str(output_file), sr_image)
                        if success:
                            processed += 1
                        else:
                            print(f"‚ùå Failed to save: {output_file}")
                            failed += 1
                    else:
                        failed += 1
                
                # Update statistics
                emotion_key = f"{split}_{emotion_name}"
                stats['by_emotion'][emotion_key] = {
                    'processed': processed,
                    'failed': failed
                }
                stats['total_processed'] += processed
                stats['total_failed'] += failed
                
                print(f"    ‚úÖ {processed:4} processed, ‚ùå {failed:2} failed")
        
        # Save statistics
        stats_file = output_path / "srgan_preprocessing_stats.json"
        with open(stats_file, 'w') as f:
            json.dump(stats, f, indent=2)
        
        # Create metadata
        metadata = {
            "preprocessing_method": "SRGAN Standard Architecture",
            "paper_compliance": "48x48 -> 192x192 (4x upscaling)",
            "model_architecture": "Standard SRGAN Generator",
            "input_size": self.input_size,
            "output_size": self.output_size,
            "scale_factor": self.scale_factor,
            "total_images_processed": stats['total_processed'],
            "total_images_failed": stats['total_failed'],
            "emotion_mapping": emotion_mapping,
            "next_steps": [
                "1. MediaPipe Face Mesh (468 landmarks)",
                "2. Key landmark selection (27 points)", 
                "3. Angular encoding (10 features)",
                "4. Classification with 8 ML models"
            ]
        }
        
        metadata_file = output_path / "preprocessing_metadata.json"
        with open(metadata_file, 'w') as f:
            json.dump(metadata, f, indent=2)
        
        print(f"\n‚úÖ SRGAN preprocessing completed!")
        print(f"üìä Total processed: {stats['total_processed']}")
        print(f"‚ùå Total failed: {stats['total_failed']}")
        print(f"üìÑ Statistics: {stats_file}")
        print(f"üìÑ Metadata: {metadata_file}")
        
        return stats

def main():
    parser = argparse.ArgumentParser(
        description="SRGAN preprocessing with standard architecture",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Test with comparison visualization
  python srgan_standard_preprocessing.py weights.h5 /path/to/raf_db /path/to/output --test-mode --create-comparison
  
  # Full preprocessing
  python srgan_standard_preprocessing.py weights.h5 /path/to/raf_db /path/to/output
  
  # Just create comparison from single image
  python srgan_standard_preprocessing.py weights.h5 --single-image /path/to/image.jpg --output-comparison comparison.jpg
        """
    )
    
    parser.add_argument('srgan_weights', help='Path to SRGAN .h5 weights file')
    parser.add_argument('input_dataset', nargs='?', help='Path to original RAF-DB dataset')
    parser.add_argument('output_dataset', nargs='?', help='Path to save preprocessed dataset')
    parser.add_argument('--test-mode', action='store_true',
                       help='Process only 5 images per emotion for testing')
    parser.add_argument('--create-comparison', action='store_true',
                       help='Create visual comparison for first processed image')
    parser.add_argument('--single-image', type=str,
                       help='Process single image for testing')
    parser.add_argument('--output-comparison', type=str, default='srgan_comparison.jpg',
                       help='Output path for comparison image')
    
    args = parser.parse_args()
    
    print("=" * 80)
    print("üéØ SRGAN STANDARD ARCHITECTURE PREPROCESSING")
    print("Paper: 48x48 ‚Üí 192x192 (4x Super-Resolution)")
    print("=" * 80)
    
    # Initialize preprocessor
    try:
        preprocessor = SRGANStandardPreprocessor(args.srgan_weights)
    except Exception as e:
        print(f"‚ùå Failed to initialize SRGAN: {e}")
        return
    
    # Single image mode
    if args.single_image:
        print(f"\nüñºÔ∏è  Processing single image: {args.single_image}")
        
        # Create comparison
        comparison = preprocessor.create_comparison_visualization(
            args.single_image, 
            args.output_comparison
        )
        
        if comparison is not None:
            print("‚úÖ Single image processing completed")
            print(f"üíæ Comparison saved to: {args.output_comparison}")
        else:
            print("‚ùå Single image processing failed")
        return
    
    # Dataset mode
    if not args.input_dataset or not args.output_dataset:
        print("‚ùå Dataset paths required for dataset processing")
        print("Use --single-image for single image testing")
        return
    
    try:
        # Process dataset
        stats = preprocessor.preprocess_dataset(
            args.input_dataset,
            args.output_dataset, 
            test_mode=args.test_mode
        )
        
        # Create comparison if requested
        if args.create_comparison:
            print(f"\nüîç Creating comparison visualization...")
            
            # Find first image for comparison
            input_path = Path(args.input_dataset)
            test_image = None
            
            for split in ['train', 'test']:
                split_path = input_path / split
                if split_path.exists():
                    for emotion_folder in split_path.iterdir():
                        if emotion_folder.is_dir():
                            images = list(emotion_folder.glob("*.jpg")) + \
                                   list(emotion_folder.glob("*.jpeg")) + \
                                   list(emotion_folder.glob("*.png"))
                            if images:
                                test_image = images[0]
                                break
                    if test_image:
                        break
            
            if test_image:
                comparison_path = Path(args.output_dataset) / "srgan_comparison.jpg"
                preprocessor.create_comparison_visualization(str(test_image), str(comparison_path))
            else:
                print("‚ö†Ô∏è  No suitable image found for comparison")
        
        print(f"\nüéâ Preprocessing completed successfully!")
        print(f"\nüìã Next steps:")
        print(f"1. Run emotion recognition training:")
        print(f"   python complete_training_pipeline.py {args.srgan_weights} {args.input_dataset} --skip-preprocessing --preprocessed-path {args.output_dataset}")
        
    except Exception as e:
        print(f"‚ùå Preprocessing failed: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()